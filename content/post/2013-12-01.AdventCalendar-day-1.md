+++
date = "2013-12-01T01:11:06+09:00"
title = "Wakame Users Group Advent Calendar 2013 1日目"
tags = ["Wakame-vdc","AdventCalendar"]
+++

# 緑山タイガ
「Eucalyptus の Advent Calendar は今年はやりません」と言いましたが、あちこちの Advent Calendar に参加を表明しているうちに、やっぱり今年もやりたくなってきたので、こっそり[^1] Advent Calendar をやろうと思います。

まぁ、ぶっちゃけると他の Advent Calendar が賑わっていく様子を見ててとても羨ましくなったんですよ。かと言って、自分から「仲間に入れてー」なんて声をかけられないシャイボーイなので、遠巻きにチラッチラッと見るのが関の山なんですけど、思えば昔からクラスの端っこに居る根暗少年でした。よくクラスに23人ぐらいスポーツ万能で喋りも面白くてちょっと女の子に黄色い声をかけられると満更でもない様子ではにかんじゃうようなスポーツ少年が居るじゃないですか？「俺ってシャイだからなぁ…」とか言っちゃう感じの、いやいやいや、くっそぉーい、「シャイ」っつーのは俺みたいに教室の隅っこで慎ましくジッとしているような人間を表すんであって、君らみたいにクラスの中心で愛を叫んじゃうような人達では断じてあってはいけないんです。

えーっと、脱線しすぎました。何の話でしたっけ？
そうそう、そんなクラスの中心に居るようなスポーツ少年と言えば、エフエム山口の[緑山タイガくん](http://www.fmy.co.jp/etc/taiga/)です。もうねプロフィールに「自分ではモテると思ってる。」とか書いてあるんすよ、少年にしてこの充実っぷり、オジさんもうね、やんなっちゃう。で、この緑山タイガくん、なんと今日12/1が誕生日です。おめでとう。意味もなくオジさん祝っちゃうよ。

# nested KVM を用いた環境で Wakame-VDC 環境の作り方

えー、もう何年も前から「オレ Wakame-VDC やるんだ」って言ってるんですが、未だに環境1つ満足に作ってきませんでした。そう、いわゆる「やるやる詐欺」ってやつです。で、そろそろ外圧がないとやらないこと確定なので、Advent Calendar に参加してみることにしました。まー、そんな私の個人的理由なんてどーでもいいと思うので、さっさと Wakame-VDC な環境を作ってみようと思います。

その前に、実はこの日記の設定がうまく行ってなく、画像をアップロードすることができないため、スクリーンショットを交えながら説明することができません。ですので、大変見辛い日記になっています。すみません。


## nested KVM な環境の準備

IaaS 環境を構築する場合、物理マシンに直接構築する場合と仮想マシン上に構築する場合があります。前者の場合は一般的ですが、後者の場合は実運用としてはあまり一般的とは言えませんが、IaaS ソフトウェアの開発やテストおよび学習環境として利用する場合は比較的よく見られる構成です。ということで、今日は私が Eucalyptus の研修や教育を行なうときに受講者に提供している環境の作り方をベースに Wakame-VDC 環境の作り方を紹介します。

あ、ちなみに nested KVM を用いた IaaS 環境の構築については、私の駄文[^2]より中井先生のブログ「[Nested KVM環境でOpenStack(RDO/Grizzly)をセットアップ](http://d.hatena.ne.jp/enakai00/20131102/1383376093)」を読むことをお勧め致します。

nested KVM についての説明はざっくり割愛しますが、一言で言えば「KVM のゲスト OS 上で KVM のホスト OS を動かす仕組み」です。で、今日ここで紹介する nested KVM 環境を構築する一番下地になる環境は、私の趣味により Gentoo Linux を用います。本当は一般的な Ubuntu とかを使うべきなんでしょうが、Ubuntu は仕事でしか使うことがないのであまり詳しくないのです。

で、まず Gentoo の環境ですが、Gentoo Linux のインストール方法とかを書いてたら日が暮れてしまうどころか日が明けてしまうので、これまたざっくり割愛して、Gentoo Linux で nested KVM を有効にする方法を説明します。「説明します」って言うほど難しい方法があるわけではなく、恐らく Ubuntu でも同じやり方だと思いますが、以下の一行を /etc/modprobe.d/kvm.conf というファイル名に保存して再起動するだけです。

Intel CPU の場合
: options kvm_intel nested=1

AMD CPU の場合
: options kvm_amd nested=1

再起動後に以下を実行して kvm のモジュールがロードされていれば OK です。
```
maculata ~ # lsmod | grep kvm
kvm_intel             117190  0
kvm                   213500  1 kvm_intel
```

もし上記が表示されない場合は、modprobe コマンドで kvm モジュールをロードしてみてください。私の環境でロードに失敗する場合は以下のようなエラーが出力されます。
```
maculata ~ # modprobe kvm_intel
FATAL: Error inserting kvm_intel (/lib/modules/3.10.17-gentoo/kernel/arch/x86/kvm/kvm-intel.ko): Operation not supported
```

このようなエラーが出力される場合は、BIOS で VT 機能が有効になっていない可能性がありますので、BIOS の設定を確認してみてください。

## Wakame-VDC の構成
まず、最初に物理的な構成ですが、本当は物理3台の nested KVM 上に作成しようと思ったんですが、欲張りすぎて 12/1 以内に終らないと困るので、日和って1台の nested KVM 環境上に複数台の仮想マシンを作成し、Wakame-VDC を立てることにします。が、複数台の構成で構築するのは私にはまだ早すぎたようです。以前から @hansode さんには「Virtualbox 使って構築するのが簡単なので、まずはそこから始めたらいいですよ」的なことを言われていたので、それに従おうかと思います。ので、成功パターンだけ知りたい方は「成功編」まで読み飛ばしてください。

## 失敗編
### 仮想マシンの準備
Wakame-VDC を動かす1段目の仮想マシンの定義は以下のようにしました。(余計な定義もありますが、華麗にスルーしてください)

* DCMGR 系用の仮想マシン定義 - /opt/dcmgr1.xml

```
<domain type='kvm'>
  <name>dcmgr1</name>
  <memory>8388608</memory>
  <currentMemory>8388608</currentMemory>
  <vcpu>2</vcpu>
  <cpu match='exact'>
    <model>core2duo</model>
    <feature policy='require' name='vmx'/>
  </cpu>
  <os>
    <type arch='x86_64' machine='pc-0.15'>hvm</type>
    <boot dev='cdrom'/>
    <boot dev='hd'/>
  </os>
  <features>
    <acpi/>
    <apic/>
    <pae/>
  </features>
  <clock offset='localtime'/>
  <on_poweroff>destroy</on_poweroff>
  <on_reboot>restart</on_reboot>
  <on_crash>restart</on_crash>
  <devices>
    <emulator>/usr/bin/qemu-kvm</emulator>
    <disk type='file' device='disk'>
      <driver name='qemu' type='qcow2'/>
      <source file='/mnt/dcmgr1.img'/>
      <target dev='hda' bus='ide'/>
      <address type='drive' controller='0' bus='0' unit='0'/>
    </disk>
    <disk type='file' device='cdrom'>
      <driver name='qemu' type='raw'/>
      <target dev='hdc' bus='ide'/>
      <source file='/mnt/CentOS-6.4-x86_64-bin-DVD1.iso'/>
      <readonly/>
      <address type='drive' controller='0' bus='0' unit='1'/>
    </disk>
    <controller type='ide' index='0'>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x1'/>
    </controller>
    <interface type='bridge'>
      <mac address='52:54:00:77:77:01'/>
      <source bridge='br0'/>
      <model type='e1000'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>
    </interface>
    <interface type='bridge'>
      <mac address='52:54:00:77:77:11'/>
      <source bridge='virbr1'/>
      <model type='e1000'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x07' function='0x0'/>
    </interface>
    <serial type='pty'>
      <target port='0'/>
    </serial>
    <console type='pty'>
      <target type='serial' port='0'/>
    </console>
    <input type='tablet' bus='usb'/>
    <input type='mouse' bus='ps2'/>
    <graphics type='vnc' port='5901' autoport='no' listen='0.0.0.0'/>
    <video>
      <model type='cirrus' vram='9216' heads='1'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/>
    </video>
    <memballoon model='virtio'>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x05' function='0x0'/>
    </memballoon>
  </devices>
</domain>
```

* Agent 系用の仮想マシン定義 - /opt/hva1.xml (DCMGR 系用の定義との差分だけ)


```
--- /opt/dcmgr1.xml     2013-11-30 06:15:12.000000000 +0900
+++ /opt/hva1.xml       2013-11-30 06:14:47.000000000 +0900
@@ -1,7 +1,7 @@
 <domain type='kvm'>
-  <name>dcmgr1</name>
-  <memory>8388608</memory>
-  <currentMemory>8388608</currentMemory>
+  <name>hva1</name>
+  <memory>4194304</memory>
+  <currentMemory>4194304</currentMemory>
   <vcpu>2</vcpu>
   <cpu match='exact'>
     <model>core2duo</model>
@@ -25,7 +25,7 @@
     <emulator>/usr/bin/qemu-kvm</emulator>
     <disk type='file' device='disk'>
       <driver name='qemu' type='qcow2'/>
-      <source file='/opt/dcmgr1.img'/>
+      <source file='/opt/hva1.img'/>
       <target dev='hda' bus='ide'/>
       <address type='drive' controller='0' bus='0' unit='0'/>
     </disk>
@@ -40,13 +40,13 @@
       <address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x1'/>
     </controller>
     <interface type='bridge'>
-      <mac address='52:54:00:77:77:01'/>
+      <mac address='52:54:00:77:77:05'/>
       <source bridge='br0'/>
       <model type='e1000'/>
       <address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>
     </interface>
     <interface type='bridge'>
-      <mac address='52:54:00:77:77:11'/>
+      <mac address='52:54:00:77:77:15'/>
       <source bridge='virbr1'/>
       <model type='e1000'/>
       <address type='pci' domain='0x0000' bus='0x00' slot='0x07' function='0x0'/>
@@ -59,7 +59,7 @@
     </console>
     <input type='tablet' bus='usb'/>
     <input type='mouse' bus='ps2'/>
-    <graphics type='vnc' port='5901' autoport='no' listen='0.0.0.0'/>
+    <graphics type='vnc' port='5905' autoport='no' listen='0.0.0.0'/>
     <video>
       <model type='cirrus' vram='9216' heads='1'/>
       <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/>
```

で、仮想マシンの定義ファイルを書いたら、今度は仮想ブリッジの定義ファイル /opt/virbr1.xml を以下の内容で書きます。

```
<network>
  <name>virbr1</name>
  <bridge name="virbr1" />
  <forward/>
  <ip address="10.168.32.1" netmask="255.255.255.0">
  </ip>
</network>
```

作成した定義ファイルを使って仮想ブリッジを作成します。
```
maculata ~ # virsh net-list
 Name                 State      Autostart     Persistent
----------------------------------------------------------
 default              active     yes           yes

maculata ~ # virsh net-define /opt/virbr1.xml
Network virbr1 defined from /opt/virbr1.xml
```

作成した仮想ブリッジを自動起動させたい場合は以下を実行します。
```
maculata ~ # virsh net-autostart virbr1
Network virbr1 marked as autostarted
```

以下を実行して、作成した仮想ブリッジを起動させます。
```
maculata ~ # virsh net-start virbr1
Network virbr1 started

maculata ~ # virsh net-list
 Name                 State      Autostart     Persistent
----------------------------------------------------------
 default              active     yes           yes
 virbr1               active     yes           yes
```

以下を実行して、仮想マシンの空のディスクイメージを作成します。
```
maculata ~ # qemu-img create -f qcow2 /opt/dcmgr1.img 300G
Formatting '/opt/dcmgr1.img', fmt=qcow2 size=322122547200 encryption=off cluster_size=65536 lazy_refcounts=off

maculata ~ # qemu-img create -f qcow2 /opt/hva1.img 100G
Formatting '/opt/hva1.img', fmt=qcow2 size=107374182400 encryption=off cluster_size=65536 lazy_refcounts=off
```

あ、ちなみに CentOS 6.4 の iso ファイルをダウンロードしておき /mnt/ に配置しておいてください。

## 仮想マシンの起動と CentOS のインストール
準備が完了したら、以下を実行して仮想マシンを起動します。

```
maculata ~ # virsh create /opt/dcmgr1.xml
Domain dcmgr1 created from /opt/dcmgr1.xml

maculata ~ # virsh create /opt/hva1.xml
Domain hva1 created from /opt/hva1.xml

```

上記を実行したら vncviewer などで仮想マシンのコンソールに接続します。私の今回の環境と前述した XML 定義により、nested KVM を動かしているマシンの 5901/tcp に接続することで、dcmgr1 のコンソールに接続できるように設定してあります。hva1 のコンソールには 5905/tcp で接続できます。

と、お約束ですみませんが、CentOS 6.4 のインストール作業の説明は割愛します。

でインストールが終了して再起動するとログインできるようになりますが一旦ここで仮想マシンの電源を落して仮想マシンの定義ファイルを修正し、DVD から起動しないように変更します。
```
maculata ~ # diff -u /opt/dcmgr1.xml.orig /opt/dcmgr1.xml
--- /opt/dcmgr1.xml.orig        2013-11-30 06:15:12.000000000 +0900
+++ /opt/dcmgr1.xml     2013-11-30 07:26:59.000000000 +0900
@@ -9,7 +9,7 @@
   </cpu>
   <os>
     <type arch='x86_64' machine='pc-0.15'>hvm</type>
-    <boot dev='cdrom'/>
+    <!--boot dev='cdrom'/-->
     <boot dev='hd'/>
   </os>
   <features>
@@ -29,13 +29,13 @@
       <target dev='hda' bus='ide'/>
       <address type='drive' controller='0' bus='0' unit='0'/>
     </disk>
-    <disk type='file' device='cdrom'>
+    <!--disk type='file' device='cdrom'>
       <driver name='qemu' type='raw'/>
       <target dev='hdc' bus='ide'/>
       <source file='/mnt/CentOS-6.4-x86_64-bin-DVD1.iso'/>
       <readonly/>
       <address type='drive' controller='0' bus='0' unit='1'/>
-    </disk>
+    </disk-->
     <controller type='ide' index='0'>
       <address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x1'/>
     </controller>
```

で、再度起動し ssh でログインします。

### Wakame-VDC - DCMGR のインストール

Wakame-VDC のインストールは[公式のドキュメント](https://github.com/axsh/wakame-vdc/tree/master/rpmbuild)を参考にします。

まずは DCMGR 用のマシンで以下を実行します。

* wakame-vdc.repo をダウンロードし /etc/yum.repos.d/ 配下に格納

```
[root@dcmgr1 ~]# curl -o /etc/yum.repos.d/wakame-vdc.repo -R https://raw.github.com/axsh/wakame-vdc/master/rpmbuild/wakame-vdc.repo
```

* epel から依存パッケージを取得できるように以下を実行

```
[root@dcmgr1 ~]# rpm -Uvh http://dlc.wakame.axsh.jp.s3-website-us-east-1.amazonaws.com/epel-release
```

* DCMGR 系のパッケージをインストールするために以下を実行して wakame-vdc-dcmgr-vmapp-config をインストール

```
[root@dcmgr1 ~]# yum install -y wakame-vdc-dcmgr-vmapp-config
(中略)
  unixODBC.x86_64 0:2.2.14-12.el6_3
  wakame-vdc.x86_64 0:13.08-20131029172613gitf8a14f9.el6
  wakame-vdc-rack-config.noarch 0:13.08-20131029172613gitf8a14f9.el6
  wakame-vdc-ruby.x86_64 0:2.0.0.247.axsh0-1
  wxBase.x86_64 0:2.8.12-1.el6.centos
  wxGTK.x86_64 0:2.8.12-1.el6.centos
  wxGTK-gl.x86_64 0:2.8.12-1.el6.centos

Dependency Updated:
  mysql-libs.x86_64 0:5.1.69-1.el6_4

Complete!
[root@dcmgr1 ~]#
```

### Wakame-VDC - HVA のインストール

次に HVA 用のマシンで以下を実行します。

* wakame-vdc.repo をダウンロードし /etc/yum.repos.d/ 配下に格納

```
[root@hva1 ~]# curl -o /etc/yum.repos.d/wakame-vdc.repo -R https://raw.github.com/axsh/wakame-vdc/master/rpmbuild/wakame-vdc.repo
```

* epel から依存パッケージを取得できるように以下を実行

```
[root@hva1 ~]# rpm -Uvh http://dlc.wakame.axsh.jp.s3-website-us-east-1.amazonaws.com/epel-release
```

で、公式のドキュメントでは「OpenVZ を使うなら OpenVZ のパッケージを入れるためのレポジトリを登録してね」って書いてありますが、ここでは折角の nested KVM 環境なので、OpenVZ は使わないです。

* HVA 系のパッケージをインストールするために以下を実行して wakame-vdc-hva-full-vmapp-config をインストール

```
[root@hva1 ~]# yum install -y wakame-vdc-hva-full-vmapp-config
```

で、インストール中に「vzctl が無いよ」とか言われちゃう…あれ？やっぱ OpenVZ 用のレポジトリを登録しないと駄目？と思い、あまり考えずに以下を実行してしまいました。

* OpenVZ 用のレポジトリを登録して再度インストール

```
[root@hva1 ~]# curl -o /etc/yum.repos.d/openvz.repo -R https://raw.github.com/axsh/wakame-vdc/master/rpmbuild/openvz.repo
[root@hva1 ~]# yum install -y wakame-vdc-hva-full-vmapp-config
```

「ハッ！ ( ﾟдﾟ)、しまった、何で俺は全部のハイパーバイザ用のパッケージを入れてんだ？インストールするなら wakame-vdc-hva-kvm-vmapp-config だけでいいんじゃね？」ってことを実行してから気付きました。まー、いいや、先に進みましょう。

### Wakame-VDC - DCMGR の設定

DCMGR 系のコンテナを有効にするために /etc/default/vdc-* なファイルに記述されている「#RUN=yes」を「RUN=yes」にします。
```
[root@dcmgr1 ~]# sed -i -e 's/^#\(RUN=yes\)/\1/' /etc/default/vdc-*
```

ドキュメントによると、全部で8つのファイルが対象になるらしいので、ちゃんと置換されているかを確認します。
```
[root@dcmgr1 ~]# grep RUN= /etc/default/vdc-*
/etc/default/vdc-collector:RUN=yes
/etc/default/vdc-dcmgr:RUN=yes
[root@dcmgr1 ~]# ls -al /etc/default/
total 36
drwxr-xr-x.  2 root root  4096 Nov 30 17:03 .
drwxr-xr-x. 99 root root 12288 Nov 30 16:48 ..
-rw-r--r--.  1 root root  1756 Feb 21  2013 nss
-rw-------.  1 root root   119 Nov 20  2009 useradd
-rw-r--r--.  1 root root   187 Nov 30 17:03 vdc-collector
-rw-r--r--.  1 root root   250 Nov 30 17:03 vdc-dcmgr
-rw-r--r--.  1 root root   271 Oct 29 17:33 wakame-vdc
```

んんん……？あれ？2つしかファイルが無いですね。あと6つのファイルはどこでしょう？インストールされている rpm を確認してみます。
```
[root@dcmgr1 ~]# rpm -qa|grep wakame-vdc-
wakame-vdc-rack-config-13.08-20131029172613gitf8a14f9.el6.noarch
wakame-vdc-ruby-2.0.0.247.axsh0-1.x86_64
wakame-vdc-13.08-20131029172613gitf8a14f9.el6.x86_64
wakame-vdc-dcmgr-vmapp-config-13.08-20131029172613gitf8a14f9.el6.noarch
```

あれあれあれ？何か気持ち少ないような気がしますね…。「yum whatprovides /etc/default/vdc-proxy」とかって叩いて以下の足りない6ファイルを持つパッケージを探してみました。

* /etc/default/vdc-proxy
* /etc/default/vdc-webui
* /etc/default/vdc-auth
* /etc/default/vdc-metadata
* /etc/default/vdc-nsa
* /etc/default/vdc-sta

で、その結果から以下を実行して足りないと思われるパッケージをインストールします。
```
[root@dcmgr1 ~]# yum install wakame-vdc-proxy-vmapp-config wakame-vdc-webui-vmapp-config wakame-vdc-auth-vmapp-config wakame-vdc-metadata-server-vmapp-config wakame-vdc-nsa-vmapp-config wakame-vdc-sta-vmapp-config
```

次に DCMGR 系コンポーネントのための設定ファイルをコピーします。

```
[root@dcmgr1 ~]# cp -f /opt/axsh/wakame-vdc/dcmgr/config/dcmgr.conf.example /etc/wakame-vdc/dcmgr.conf
[root@dcmgr1 ~]# cp -f /opt/axsh/wakame-vdc/frontend/dcmgr_gui/config/database.yml.example /etc/wakame-vdc/dcmgr_gui/database.yml
[root@dcmgr1 ~]# cp -f /opt/axsh/wakame-vdc/frontend/dcmgr_gui/config/dcmgr_gui.yml.example /etc/wakame-vdc/dcmgr_gui/dcmgr_gui.yml
[root@dcmgr1 ~]# cp -f /opt/axsh/wakame-vdc/frontend/dcmgr_gui/config/instance_spec.yml.example /etc/wakame-vdc/dcmgr_gui/instance_spec.yml
[root@dcmgr1 ~]# cp -f /opt/axsh/wakame-vdc/frontend/dcmgr_gui/config/load_balancer_spec.yml.example /etc/wakame-vdc/dcmgr_gui/load_balancer_spec.yml
```

次に proxy の設定をテンプレートを元に生成します。
手順には https://github.com/axsh/wakame-vdc/blob/master/tests/vdc.sh.d/proxy.conf.tmpl って書いてありますが、apache を使う場合は https://github.com/axsh/wakame-vdc/blob/master/tests/vdc.sh.d/apache-proxy.conf.tmpl です。

```
[root@dcmgr1 ~]# echo "$(eval "VDC_ROOT=/var/lib/wakame-vdc; echo \"$(curl -s https://raw.github.com/axsh/wakame-vdc/master/tests/vdc.sh.d/apache-proxy.conf.tmpl)\"")" > /etc/wakame-vdc/proxy.conf
```

次にデータベースの設定をしますが、まず MySQL を起動させます。
```
[root@dcmgr1 ~]# /etc/init.d/mysqld status
mysqld is stopped
[root@dcmgr1 ~]# /etc/init.d/mysqld start
Starting mysqld:                                           [  OK  ]

[root@dcmgr1 ~]# chkconfig mysqld on
```

そしてドキュメントに書かれているような設定になっているかを確認します。
```
[root@dcmgr1 ~]# grep database_uri /etc/wakame-vdc/dcmgr.conf
database_uri 'mysql2://localhost/wakame_dcmgr?user=root'

[root@dcmgr1 ~]# grep ^development -A6 /etc/wakame-vdc/dcmgr_gui/database.yml
development:
  adapter: mysql2
  database: wakame_dcmgr_gui
  host: localhost
  user: root
  password:

```

問題なさそうですね。続いて AMQP の設定を確認します。

```
[root@dcmgr1 ~]# grep ^amqp_server_uri /etc/wakame-vdc/dcmgr.conf
amqp_server_uri 'amqp://localhost/'
[root@dcmgr1 ~]# grep AMQP_ /etc/default/vdc-collector /etc/default/vdc-nsa /etc/default/vdc-sta
/etc/default/vdc-collector:#AMQP_ADDR=127.0.0.1
/etc/default/vdc-collector:#AMQP_PORT=5672
/etc/default/vdc-nsa:#AMQP_ADDR=127.0.0.1
/etc/default/vdc-nsa:#AMQP_PORT=5672
/etc/default/vdc-sta:#AMQP_ADDR=127.0.0.1
/etc/default/vdc-sta:#AMQP_PORT=5672
```

た、たぶんこれでいいんだよね？ RabbitMQ が dcmgr1 で起動させてるはずなので、デフォルトで 127.0.0.1:5672 にアクセスするのかな？かな？

次行きましょ…。

### Wakame-VDC - HVA の設定

HVA のコンテナを有効にするために /etc/default/vdc-* なファイルに記述されている「#RUN=yes」を「RUN=yes」にします。

```
[root@hva1 ~]# sed -i -e 's/^#\(RUN=yes\)/\1/' /etc/default/vdc-*
[root@hva1 ~]# grep RUN= /etc/default/vdc-*
/etc/default/vdc-fluentd:RUN=yes
/etc/default/vdc-hva:RUN=yes
[root@hva1 ~]# ls -al /etc/default/
total 36
drwxr-xr-x.   2 root root  4096 Nov 30 17:04 .
drwxr-xr-x. 103 root root 12288 Nov 30 16:58 ..
-rw-r--r--.   1 root root  1756 Feb 21  2013 nss
-rw-------.   1 root root   119 Nov 20  2009 useradd
-rw-r--r--.   1 root root   134 Nov 30 17:04 vdc-fluentd
-rw-r--r--.   1 root root   233 Nov 30 17:04 vdc-hva
-rw-r--r--.   1 root root   271 Oct 29 17:33 wakame-vdc
```

たぶん、これで問題ないはず…。続いて AMQP の設定をします。私の環境では /etc/default/vdc-hva の AMQP に関する設定と NODE_ID の値を以下ように設定しました。
```
## agent params
AMQP_ADDR=10.168.32.73
AMQP_PORT=5672
NODE_ID=hva1
```

そして、HVA 用の設定ファイルを作ります。

```
[root@hva1 ~]# cp -f /opt/axsh/wakame-vdc/dcmgr/config/hva.conf.example /etc/wakame-vdc/hva.conf
```

で、ドキュメントでは次に「デモ用データが必要だったら以下をやっちゃいなよ」って書いてありまして、まぁ必要かどうか右も左も分からない身としてはこの先どうしていいか不明なので、大人しく実行してみることにします。(；´Д`A

まずは必要なパッケージをインストールします。

```
[root@dcmgr1 ~]# yum install -y wakame-vdc-vdcsh
```

次にドキュメントに書かれているコマンドを実行します。ちょっと長いですが、全部貼ります。

```
[root@dcmgr1 ~]# /opt/axsh/wakame-vdc/tests/vdc.sh init
mode=$1 (line 146: /opt/axsh/wakame-vdc/tests/vdc.sh, pwd: /root)
case ${mode} in (line 148: /opt/axsh/wakame-vdc/tests/vdc.sh, pwd: /root)
init_db (line 162: /opt/axsh/wakame-vdc/tests/vdc.sh, pwd: /root)
Dropping the database is potentially a very bad thing to do.
Any data stored in the database will be destroyed.

Do you really want to drop the 'wakame_dcmgr' database [y/N] mysqladmin: DROP DATABASE wakame_dcmgr failed;
error: 'Can't drop database 'wakame_dcmgr'; database doesn't exist'
Dropping the database is potentially a very bad thing to do.
Any data stored in the database will be destroyed.

Do you really want to drop the 'wakame_dcmgr_gui' database [y/N] mysqladmin: DROP DATABASE wakame_dcmgr_gui failed;
error: 'Can't drop database 'wakame_dcmgr_gui'; database doesn't exist'
executing 'rake db:init' => dcmgr ...
** Invoke db:init (first_time)
** Invoke db:up (first_time)
** Invoke environment (first_time)
** Execute environment
** Execute db:up
** Execute db:init
WARN: deprecated task. Please use db:up.

real    0m11.625s
user    0m1.238s
sys     0m0.116s
executing 'rake db:init' => frontend/dcmgr_gui ...
** Invoke db:init (first_time)
** Invoke environment (first_time)
** Execute environment
** Execute db:init

real    0m3.671s
user    0m2.702s
sys     0m0.234s
.... rake oauth:create_consumer[a-shpoolxx]
../bin/vdc-manage host add hva.demo1 --force --uuid hn-demo1 --cpu-cores 100 --memory-size 400000 --disk-space 500000 --hypervisor openvz --arch x86_64 (cwd: /opt/axsh/wakame-vdc/dcmgr)
hn-demo1
../bin/vdc-manage storage iscsi add sta.demo1 --uuid sn-demo1 --base-path /opt/axsh/wakame-vdc/tmp/volumes --disk-space 1048576 --ipaddr 192.168.32.73 --snapshot-base-path /opt/axsh/wakame-vdc/tmp/snap (cwd: /opt/axsh/wakame-vdc/dcmgr)
sn-
../bin/vdc-manage backupstorage add --uuid bkst-demo1 --display-name='local storage' --base-uri='file:///opt/axsh/wakame-vdc/tmp/images/' --storage-type=local --description='local backup storage under /opt/axsh/wakame-vdc/tmp/images/' --node-id=bksta.demo1 (cwd: /opt/axsh/wakame-vdc/dcmgr)
bkst-demo1
../bin/vdc-manage backupstorage add --uuid bkst-demo2 --display-name='webdav storage' --base-uri='http://localhost:8080/images/' --storage-type=webdav --description='nginx based webdav storage' --node-id=bksta.demo2 (cwd: /opt/axsh/wakame-vdc/dcmgr)
bkst-demo2
ls: cannot access /opt/axsh/wakame-vdc/tests/vdc.sh.d/image.enabled/image-*.meta: No such file or directory
Image meta files to be registered:
>---------------------------------------<
/opt/axsh/wakame-vdc/tests/vdc.sh.d/image.available/image-cassandra.meta
/opt/axsh/wakame-vdc/tests/vdc.sh.d/image.available/image-centos1d.meta
/opt/axsh/wakame-vdc/tests/vdc.sh.d/image.available/image-lb.meta
/opt/axsh/wakame-vdc/tests/vdc.sh.d/image.available/image-lbnode.meta
/opt/axsh/wakame-vdc/tests/vdc.sh.d/image.available/image-lucid0.meta
/opt/axsh/wakame-vdc/tests/vdc.sh.d/image.available/image-lucid1.meta
/opt/axsh/wakame-vdc/tests/vdc.sh.d/image.available/image-lucid2.meta
/opt/axsh/wakame-vdc/tests/vdc.sh.d/image.available/image-lucid5d.meta
/opt/axsh/wakame-vdc/tests/vdc.sh.d/image.available/image-lucid5.meta
/opt/axsh/wakame-vdc/tests/vdc.sh.d/image.available/image-lucid6d.meta
/opt/axsh/wakame-vdc/tests/vdc.sh.d/image.available/image-lucid6.meta
/opt/axsh/wakame-vdc/tests/vdc.sh.d/image.available/image-lucid7d.meta
/opt/axsh/wakame-vdc/tests/vdc.sh.d/image.available/image-lucid7.meta
/opt/axsh/wakame-vdc/tests/vdc.sh.d/image.available/image-secgtest.meta
>---------------------------------------<
/opt/axsh/wakame-vdc/tests/vdc.sh.d/demodata_images.sh: line 34: cd: /opt/axsh/wakame-vdc/tmp/images: No such file or directory
```

と、ここでディレクトリ /opt/axsh/wakame-vdc/tmp/images が無いと怒られます。

```
[root@dcmgr1 ~]# ls -al /opt/axsh/wakame-vdc/
total 48
drwxr-xr-x. 12 root root 4096 Nov 30 20:10 .
drwxr-xr-x.  3 root root 4096 Nov 30 16:43 ..
drwxr-xr-x.  5 root root 4096 Nov 30 16:43 client
drwxr-xr-x.  5 root root 4096 Nov 30 16:43 contrib
drwxr-xr-x. 11 root root 4096 Nov 30 16:43 dcmgr
drwxr-xr-x.  4 root root 4096 Nov 30 16:43 dolphin
drwxr-xr-x.  4 root root 4096 Nov 30 16:43 frontend
lrwxrwxrwx.  1 root root   26 Nov 30 16:43 images -> /var/lib/wakame-vdc/images
lrwxrwxrwx.  1 root root   29 Nov 30 16:43 instances -> /var/lib/wakame-vdc/instances
drwxr-xr-x.  7 root root 4096 Nov 30 16:43 rpmbuild
drwxr-xr-x.  6 root root 4096 Nov 30 16:43 ruby
lrwxrwxrwx.  1 root root   24 Nov 30 16:43 snap -> /var/lib/wakame-vdc/snap
drwxr-xr-x.  4 root root 4096 Nov 30 20:13 tests
drwxr-xr-x.  6 root root 4096 Nov 30 16:43 vdc-fluentd
drwxr-xr-x.  4 root root 4096 Nov 30 16:43 vendor
lrwxrwxrwx.  1 root root   27 Nov 30 16:43 volumes -> /var/lib/wakame-vdc/volumes
```

おや？確かに /opt/axsh/wakame-vdc/tmp/images が無いですね。じゃぁ作りましょう。

```
[root@dcmgr1 ~]# mkdir -p /opt/axsh/wakame-vdc/tmp/images
```

あと、↑上の ls の結果では色が付いてないので分かりませんが、/var/lib/wakame-vdc/instances ディレクトリに対するシンボリックリンクがリンク切れになってますので、/var/lib/wakame-vdc/ 配下を確認してみます。

```
[root@dcmgr1 ~]# ls -al /var/lib/wakame-vdc/
total 24
drwxr-xr-x.  5 root root 4096 Nov 30 17:12 .
drwxr-xr-x. 32 root root 4096 Nov 30 17:12 ..
drwxr-xr-x.  2 root root 4096 Oct 29 17:53 images
drwxr-xr-x.  2 root root 4096 Oct 29 17:53 snap
lrwxrwxrwx.  1 root root   83 Nov 30 16:43 trema -> /opt/axsh/wakame-vdc/dcmgr/vendor/bundle/ruby/2.0.0/bundler/gems/trema-ad6792404569
drwxr-xr-x.  2 root root 4096 Oct 29 17:53 volumes
```

はい、やはり無いので作ります。

```
[root@dcmgr1 ~]# mkdir -p /var/lib/wakame-vdc/instances
```

で、もう一度 init を実行します。

```
[root@dcmgr1 ~]# /opt/axsh/wakame-vdc/tests/vdc.sh init


Tasks:
  gui-manage account sub-command  # Operations for accounts
  gui-manage help [TASK]          # Describe available tasks or one specific task
  gui-manage user sub-command     # Operations for users

gui-manage>> account add --name="demo1" --uuid=a-demo1
a-demo1
gui-manage>> user add --name="demo1" --uuid=u-demo1 --login_id=demo1 --password=demo1 --primary-account-id=a-demo1 --locale="ja" --time-zone="Asia/Tokyo"
uuid: u-demo1
login_id: demo1
password: demo1
gui-manage>> user associate u-demo1 --account-ids "a-demo1"
gui-manage>> account quota set a-demo1 instance.count 10.0
gui-manage>> account quota set a-demo1 instance.quota_weight 10.0
gui-manage>> account quota set a-demo1 load_balancer.count 10.0
gui-manage>> [root@dcmgr1 ~]#

```

うん、成功かな？

で、今更ですが RabbitMQ を起動させるのを忘れていたことに気付いたので、以下を実行して rabbitmq-server を起動させます。
```
[root@dcmgr1 dcmgr]# /etc/init.d/rabbitmq-server start
Starting rabbitmq-server: SUCCESS
rabbitmq-server.
```

さて、これからどうするんだろう…？どうしていいのかわからなかったので、/opt/axsh/wakame-vdc/tests/vdc.sh を見てましたら function run_standalone() の記述を見つけたので、それっぽく実行してみました。

* vdc-collector の実行

```
[root@dcmgr1 dcmgr]# ./bin/collector 2>&1 | tee ../tmp/vdc-collector.log
2013-11-30 21:03:28 Node thr=#<Thread:0x007f13cdb77d10> [INFO]: Started : AMQP Server=amqp://localhost/, ID=collector.master, token=3a93c
```

* vdc-nsa の実行

```
[root@dcmgr1 dcmgr]# ./bin/nsa -i hva1 2>&1 | tee ../tmp/vdc-nsa.log
I, [2013-12-01T16:01:22.404182 #14653]  INFO -- SuperviseDnsmasq: network_name: nwg-shnet
I, [2013-12-01T16:01:22.406396 #14653]  INFO -- SuperviseDnsmasq: Using dnsmasq v["2", "48"]: configuration version < 2.53
D, [2013-12-01T16:01:22.406579 #14653] DEBUG -- SuperviseDnsmasq: start_dnsmasq begin
2013-12-01 16:01:22 Node thr=#<Thread:0x007f209693fd10> [INFO]: Started : AMQP Server=amqp://localhost/, ID=nsa.hva1, token=c2aed
I, [2013-12-01T16:01:22.458344 #14653]  INFO -- SuperviseDnsmasq: refreshed dnsmasq conf
```

* vdc-hva の実行

```
[root@hva1 dcmgr]# ./bin/hva -i hva1 2>&1 | tee ../tmp/vdc-hva.log
2013-12-01 16:03:35 RpcChannel thr=#<Thread:0x007fbeb76ebd10> [ERROR]: No such endpoints
2013-12-01 16:03:35 RpcChannel thr=#<Thread:0x007fbeb76ebd10> [ERROR]: No such endpoints
```

あ…れ…？何でエンドポイントが無いって言われんだろう？うーん、動きません…。さて、仕組みを理解してないので、こーゆーときボロが出ます。(；´Д`A

とりあえず、dcmgr1 で動いているプロセスや LISTEN しているポートなどを見ていたんですが、

```
[root@dcmgr1 dcmgr]# lsof -i:5672 -n
COMMAND     PID     USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
nsa       14653     root   10u  IPv4  93487      0t0  TCP 127.0.0.1:41726->127.0.0.1:amqp (ESTABLISHED)
beam.smp  30371 rabbitmq   14u  IPv6  75317      0t0  TCP *:amqp (LISTEN)
beam.smp  30371 rabbitmq   16u  IPv6  75409      0t0  TCP 127.0.0.1:amqp->127.0.0.1:41721 (ESTABLISHED)
beam.smp  30371 rabbitmq   17u  IPv6  93488      0t0  TCP 127.0.0.1:amqp->127.0.0.1:41726 (ESTABLISHED)
collector 30473     root   11u  IPv4  75408      0t0  TCP 127.0.0.1:41721->127.0.0.1:amqp (ESTABLISHED)
```

うーん、IPv4 で LISTEN してない…。設定どーなってんのさ？
```
[root@dcmgr1 dcmgr]# ls -al /etc/rabbitmq/
total 16
drwxr-xr-x.   2 root root  4096 Aug 24 18:42 .
drwxr-xr-x. 101 root root 12288 Dec  1 03:38 ..
[root@dcmgr1 dcmgr]#
```
あぁ…設定が無いですよ…空っぽっす。ってことで、設定を作って rabbitmq-server を再起動しました。
```
[root@dcmgr1 dcmgr]# cat /etc/rabbitmq/rabbitmq-env.conf
RABBITMQ_NODE_IP_ADDRESS=0.0.0.0
[root@dcmgr1 dcmgr]# lsof -n -i:5672
COMMAND    PID     USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
beam.smp 15472 rabbitmq   14u  IPv4  95423      0t0  TCP *:amqp (LISTEN)
```

ってことで、もー一度 vdc-hva を起動します。
```
[root@hva1 dcmgr]# ./bin/hva -i hva1 2>&1 | tee ../tmp/vdc-hva.log
2013-12-01 16:38:30 RpcChannel thr=#<Thread:0x007f89b82a7d28> [ERROR]: No such endpoints
2013-12-01 16:38:30 RpcChannel thr=#<Thread:0x007f89b82a7d28> [ERROR]: No such endpoints
```

お、おぅ、AMQP とかの問題じゃなかったのかな…？これはもうどこを見るべきなのかわからない…orz

ML とかで質問するとか色々と手はあるんですが、えー、ちょっとそんな時間ないので、別の方法にすることにします。(；´Д`A

## 成功編

さて、気をとりなおして次は [VirtualBox 用デモイメージを使った環境の作り方](http://wakameusersgroup.org/demo_image.html) を参考にして All-in-One な環境を作ろうと思います。

### デモイメージの準備

VirtualBox のデモイメージをダウンロードします。
```
maculata wakame # mkdir -p wakame
maculata wakame # cd wakame/
maculata wakame # wget http://dlc.wakame.axsh.jp/demo/1box/vmdk/1box-openvz.netfilter.x86_64.vmdk.20130709.zip
maculata wakame # unzip 1box-openvz.netfilter.x86_64.vmdk.20130709.zip
Archive:  1box-openvz.netfilter.x86_64.vmdk.20130709.zip
  inflating: 1box-openvz.netfilter.x86_64.vmdk

```

VirtualBox のイメージを KVM のイメージに変換します。

```
maculata wakame # qemu-img convert -f vmdk 1box-openvz.netfilter.x86_64.vmdk -O qcow2 1box-openvz.netfilter.x86_64.qcow2
maculata wakame # ls -al
total 8680401
drwxr-xr-x 2 root root        224 Nov 30 20:13 .
drwx------ 8 root root        440 Nov 30 20:09 ..
-rw-r--r-- 1 root root 3506110464 Nov 30 20:14 1box-openvz.netfilter.x86_64.qcow2
-rw-r--r-- 1 root root 3506438144 Jul  9 18:56 1box-openvz.netfilter.x86_64.vmdk
-rw-r--r-- 1 root root 1867629926 Jul  9 19:02 1box-openvz.netfilter.x86_64.vmdk.20130709.zip
```

### 仮想マシン用のネットワークを作成

ドキュメントには 10.0.2.2/24 のネットワークと Internal Network のことが書いてあるので、以下の定義の仮想ブリッジを作成します。
```
maculata wakame # cat /opt/virbr2.xml
<network>
  <name>virbr2</name>
  <bridge name="virbr2" />
  <forward/>
  <ip address="10.0.2.2" netmask="255.255.255.0">
  </ip>
</network>
maculata wakame # virsh net-define /opt/virbr2.xml
Network virbr2 defined from /opt/virbr2.xml

maculata wakame # virsh net-autostart virbr2
Network virbr2 marked as autostarted

maculata wakame # virsh net-start virbr2
Network virbr2 started

maculata wakame # cat /opt/virbr3.xml
<network>
  <name>virbr3</name>
  <bridge name="virbr3" />
</network>

maculata wakame # virsh net-define /opt/virbr3.xml
Network virbr3 defined from /opt/virbr3.xml

maculata wakame # virsh net-autostart virbr3
Network virbr3 marked as autostarted

maculata wakame # virsh net-start virbr3
Network virbr3 started

maculata wakame # virsh net-list
 Name                 State      Autostart     Persistent
----------------------------------------------------------
 default              active     yes           yes
 virbr1               active     yes           yes
 virbr2               active     yes           yes
 virbr3               active     yes           yes
```

### 仮想マシンの定義を作成

ドキュメントの記述を参考に以下の仮想マシンの定義を作成しました。
```
<domain type='kvm'>
  <name>wakame-vdc-1box</name>
  <memory>3145728</memory>
  <currentMemory>3145728</currentMemory>
  <vcpu>2</vcpu>
  <cpu match='exact'>
    <model>core2duo</model>
    <feature policy='require' name='vmx'/>
  </cpu>
  <os>
    <type arch='x86_64' machine='pc-0.15'>hvm</type>
    <boot dev='hd'/>
  </os>
  <features>
    <acpi/>
    <apic/>
    <pae/>
  </features>
  <clock offset='localtime'/>
  <on_poweroff>destroy</on_poweroff>
  <on_reboot>restart</on_reboot>
  <on_crash>restart</on_crash>
  <devices>
    <emulator>/usr/bin/qemu-kvm</emulator>
    <disk type='file' device='disk'>
      <driver name='qemu' type='qcow2'/>
      <source file='/opt/wakame/1box-openvz.netfilter.x86_64.qcow2'/>
      <target dev='hda' bus='ide'/>
      <address type='drive' controller='0' bus='0' unit='0'/>
    </disk>
    <controller type='ide' index='0'>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x1'/>
    </controller>
    <interface type='bridge'>
      <mac address='52:54:00:77:77:05'/>
      <source bridge='virbr2'/>
      <model type='e1000'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>
    </interface>
    <interface type='bridge'>
      <mac address='52:54:00:77:77:15'/>
      <source bridge='virbr3'/>
      <model type='e1000'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x07' function='0x0'/>
    </interface>
    <serial type='pty'>
      <target port='0'/>
    </serial>
    <console type='pty'>
      <target type='serial' port='0'/>
    </console>
    <input type='tablet' bus='usb'/>
    <input type='mouse' bus='ps2'/>
    <graphics type='vnc' port='5905' autoport='no' listen='0.0.0.0'/>
    <video>
      <model type='cirrus' vram='9216' heads='1'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/>
    </video>
    <memballoon model='virtio'>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x05' function='0x0'/>
    </memballoon>
  </devices>
</domain>
```

### 仮想マシン (Wakame-VDC) の起動

では、早速起動してみます。

```
maculata wakame # virsh create ../wakame-vdc-1box.xml
Domain wakame-vdc-1box created from ../wakame-vdc-1box.xml
```

で、仮想マシンは起動すると色々と Wakame-VDC のための初期設定を行いますので、しばらく待ちます。

ちなみに仮想マシンのコンソールがログインプロンプトに変化していたら初期設定完了です。


あ、あと、私の環境は以下のようになっているため、

 [PC(192.168.32.19)] -- (192.168.32.0/24) --> [nested KVM host (192.168.32.20)] -- (10.0.2.0/24) --> [仮想マシン(10.0.2.15)]

直接 PC から Wakame-VDC の環境にリーチできないので、以下のように stone を用いて WebUI の画面にアクセスできるようにしています。
```
maculata wakame # stone 10.0.2.15:9000 9000
Dec  1 10:33:43.858872 139818342573824 start (2.3e) [708]
Dec  1 10:33:44.006224 139818342573824 stone 3: 10.0.2.15:9000 <- 0.0.0.0:9000
```

### Wakame-VDC を使ってみる

無事動いているようなので、ブラウザで Wakame-VDC の WebUI にアクセスしてみます。ドキュメントにも書いてあるように、「Username: demo」「Password: demo」です。

ログインしたらまず最初にセキュリティグループを作成します。左メニューの下のほうに「セキュリティグループ」のリンクがあるのでクリックすると、右側にページが表示され、ページ上部にある「セキュリティグループを作成」をクリックすると、以下のようなダイアログが表示され値が入力できますので、適宜値を入れて「作成」をクリックします。

次にキーペアを作成します。同じくメニューの「キーペア」をクリックし「キーペアを作成」をクリックし、適宜値を入れて「作成」をクリックします。

では、インスタンスを起動してみます。メニューの「マシンイメージ」をクリックし起動に使用するイメージを選択し、画面上部の「インスタンスを起動」をクリックし、適宜値を入れて「起動」をクリックします。

メニューの「インスタンス」をクリックすると、起動したインスタンスの状態が Initializing になっていますが、しばらくしてから更新すると running に遷移しますので、そうなればインスタンスの起動が成功です。


最後に先程作成したキーペアを用いてインスタンスに ssh でアクセスしてみます。
```
maculata wakame # ssh -i ssh-sr6yw6mh.pem root@10.0.2.100
The authenticity of host '10.0.2.100 (10.0.2.100)' can't be established.
RSA key fingerprint is b8:bb:02:7d:75:02:66:f6:61:64:d4:50:a1:be:6c:f2.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '10.0.2.100' (RSA) to the list of known hosts.
[root@smuuhb12 ~]#
```

はい、無事アクセスできました。

で、ここまできて「あれ？このデモイメージって、そもそも OpenVZ を使うんだから、nested KVM 別に要らなくね？」と思いましたが、やっちまったものは仕方ないです。

[^1]: ML にポストした時点で「こっそり」じゃないけど…
[^2]: 私のやり方はけっこう適当でいい加減なので…
